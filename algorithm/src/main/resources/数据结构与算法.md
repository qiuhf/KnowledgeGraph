# 基本概念

## 评估算法优劣的核心指标是什么？

- 时间复杂度（流程决定）
- 额外空间复杂度（流程决定）
- 常数项时间（实现细节决定）

##  什么是时间复杂度？时间复杂度怎么估算？

- 常数时间的操作
- 确定算法流程的总操作数量与样本数量之间的表达式关系
- 只看表达式最高阶项的部分

## 时间复杂度的意义？

​        当我们要处理的样本量很大很大时，我们会发现低阶项是什么不是最重要的；每一项的系数是什么，不是最重要的。真正重要的就是最高阶项是什么。

​        这就是时间复杂度的意义，它是衡量算法流程的复杂程度的一种指标，该指标只与数据量有关，与过程之外的优化无关。

## 额外空间复杂度

​        你要实现一个算法流程，在实现算法流程的过程中，你需要开辟一些空间来支持你的算法流程。

> 作为输入参数的空间，不算额外空间。作为输出结果的空间，也不算额外空间。因为这些都是必要的、和现实目标有关的。所以都不算。
>

但除此之外，你的流程如果还需要开辟空间才能让你的流程继续下去。这部分空间就是额外空间。如果你的流程只需要开辟有限几个变量，额外空间复杂度就是O(1)。

## 何为常数时间的操作？

​        如果一个操作的执行时间不以具体样本量为转移，每次执行时间都是固定时间。称这样的操作为常数时间的操作。

## 常见的常数时间的操作

- 常见的算术运算（+、-、*、/、% 等）
- 常见的位运算（>>、>>>、<<、|、&、^等）
- 赋值、比较、自增、自减操作等
- 数组寻址操作

>  总之，执行时间固定的操作都是常数时间的操作。反之，执行时间不固定的操作，都不是常数时间的操作

## 如何确定算法流程的总操作数量与样本数量之间的表达式关系？

1. 想象该算法流程所处理的数据状况，要按照最差情况来。
2. 把整个流程彻底拆分为一个个基本动作，保证每个动作都是常数时间的操作。
3. 如果数据量为N，看看基本动作的数量和N是什么关系。

## 算法流程的常数项的比拼方式

​    放弃理论分析，生成随机数据直接测。

> 为什么不去理论分析？
>
> 不是不能纯分析，而是没必要。因为不同常数时间的操作，虽然都是固定时间，但还是有快慢之分的。如位运算的常数时间远小于算术运算的常数时间，这两个运算的常数时间又远小于数组寻址的时间。

​     所以如果纯理论分析，往往会需要非常多的分析过程。都已经到了具体细节的程度，莫不如交给实验数据好了。

## 如何确定算法流程的时间复杂度？

​       当完成了表达式的建立，只要把最高阶项留下即可。低阶项都去掉，高阶项的系数也去掉。

> 记为：O(忽略掉系数的高阶项)

## 排序算法的稳定性

​     **稳定性**是指同样大小的样本再排序之后不会改变相对次序

> 对基础类型来说，稳定性毫无意义
> 对非基础类型来说，稳定性有重要意义

## 常见的时间复杂度?

   *排名从好到差*：

1. O(1)   
2. O(logN)   
3. O(N)   
4. O(N*logN)   
5. O(N^2)   O(N^3)   …   O(N^K)
6. O(2^N)   O(3^N)   …   O(K^N)
7. O(N!)

## Java运算符优先级

 	优先级*从上至下递减*

| 类别     | 操作符                                     | 关联性   |
| :------- | :----------------------------------------- | :------- |
| 后缀     | () [] . (点操作符)                         | 左到右   |
| 一元     | + + - ！〜                                 | 从右到左 |
| 乘性     | * /％                                      | 左到右   |
| 加性     | + -                                        | 左到右   |
| 移位     | >> >>>  <<                                 | 左到右   |
| 关系     | >> = << =                                  | 左到右   |
| 相等     | ==  !=                                     | 左到右   |
| 按位与   | ＆                                         | 左到右   |
| 按位异或 | ^                                          | 左到右   |
| 按位或   | \|                                         | 左到右   |
| 逻辑与   | &&                                         | 左到右   |
| 逻辑或   | \| \|                                      | 左到右   |
| 条件     | ？：                                       | 从右到左 |
| 赋值     | = + = - = * = / =％= >> = << =＆= ^ = \| = | 从右到左 |
| 逗号     | ，                                         | 左到右   |

## 认识异或运算

  **异或运算**：相同为0，不同为1
  **同或运算**：相同以1，不同为0

> 异或运算可记成无进位相加！

## 比较器

1. 实质就是重载比较运算符 
2. 可应用在特殊标准的排序上 
3. 应用在根据特殊标准排序的结构上
4. 写代码变得异常容易，还用于范型编程 

> 任何比较器的统一约定
>
> 谁小谁优先，即如下方法：
> @Override
> public int compare(T o1, T o2) ;
> 返回负数的情况，就是o1比o2优先的情况
> 返回正数的情况，就是o2比o1优先的情况
> 返回零的情况，就是o1与o2同样优先的情况

## 递归

​      递归底层是利用系统**栈**来实现的, 任何递归函数都一定可以改成非递归

>形如: 
>
>`T(N) = a * T(N/b) + O(N^d)`(其中的a、b、d都是常数)
>
>的递归函数，可以直接通过**Master公式**来确定时间复杂度:
>1. 如果 log(b,a) < d，复杂度为O(N^d)
>2. 如果 log(b,a) > d，复杂度为O(N^log(b,a))
>3. 如果 log(b,a) == d，复杂度为O(N^d  * logN)

## 二叉树先序、中序、后序遍历

**先序**：
	任何子树的处理顺序都是，先头节点、再左子树、然后右子树
**中序**：
	任何子树的处理顺序都是，先左子树、再头节点、然后右子树
**后序**：
	任何子树的处理顺序都是，先左子树、再右子树、然后头节点

>理解递归序
>
>1. 先序、中序、后序都可以在递归序的基础上加工出来
>2. 第一次到达一个节点就打印就是先序、第二次打印即中序、第三次即后序

## 二叉树序列化和反序列化

​	通过**先序**、**后序**或者**按层(宽度优先)**遍历的方式序列化和反序列化

>无法通过中序遍历的方式实现序列化和反序列化
>
>因为不同的两棵树，可能得到同样的中序序列，即使补空位置也可能一样。
>比如
>        __ 2             1 __ 
>     /           和              \
>   1                                 2
>补足空位置的中序遍历结果都是{ null, 1, null, 2, null}

## 贪心算法

1. 最自然智慧的算法
2. 用一种局部最功利的标准，总是做出在当前看来是最好的选择
3. 难点在于证明局部最功利的标准可以得到全局最优解
4. 对于贪心算法的学习主要以增加阅历和经验为主

## 贪心算法求解的标准过程

1. 分析业务
2. 根据业务逻辑找到不同的贪心策略
3. 对于能举出反例的策略直接跳过，不能举出反例的策略要证明有效性

> 这往往是特别困难的，要求数学能力很高且不具有统一的技巧性

## 图结构的表达

1. 邻接表法
2. 邻接矩阵法
3. 除此之外还有其他众多的方式

## 图的宽度优先&深度优先遍历

  **宽度优先遍历**

1. 利用**队列**实现
2. 从源节点开始依次按照宽度进队列，然后弹出
3. 每弹出一个点，把该节点所有没有进过队列的邻接点放入队列
4. 直到队列变空

  **深度优先遍历**

1. 利用**栈**实现
2. 从源节点开始把节点按照深度放入栈，然后弹出
3. 3，每弹出一个点，把该节点下一个没有进过栈的邻接点放入栈
4. 直到栈变空 

# 数据结构

## 栈和队列

​	**栈**：数据先进后出，犹如弹匣
​	**队列**：数据先进先出，好似排队

## 哈希表

   哈希表在使用层面上可以理解为一种集合结构

1. 如果只有key，没有伴随数据value，可以使用`HashSet`结构
2. 如果既有key，又有伴随数据value，可以使用`HashMap`结构

>有无伴随数据，是HashMap和HashSet唯一的区别，底层实际结构是一回事

​     使用哈希表增(put)、删(remove)、改(put)和查(get)的操作，可以认为时间复杂度为 O(1)，但是常数时间比较大 

> 放入哈希表的对象
>
> 如果是基础类型，内部按值传递，内存占用是这个对象的大小 
>
> 如果不是基础类型，内部按引用传递，内存占用是8字节

## 有序表

​    有序表在使用层面上可以理解为一种集合结构，有序表把key按照顺序组织起来，而哈希表完全不组织

1. 如果只有key，没有伴随数据value，可以使用`TreeSet`结构
2. 如果既有key，又有伴随数据value，可以使用`TreeMap`结构

> 有无伴随数据，是TreeSet和TreeMap唯一的区别，底层实际结构是一回事

​    红黑树、AVL树、size-balance-tree和跳表等都属于有序表结构，只是底层具体实现不同

​    有序表在使用时，比哈希表功能多，时间复杂度都是O(logN)

> 放入有序表的对象
>
> 如果是基础类型，内部按值传递，内存占用是这个对象的大小 
>
> 如果不是基础类型，内部按引用传递，内存占用是8字节



## 堆结构

1. 堆结构就是用数组实现的**完全二叉树**结构

2. 完全二叉树中如果每棵子树的最大值都在顶部就是`大根堆`

3. 完全二叉树中如果每棵子树的最小值都在顶部就是`小根堆`

4. 堆结构的heapInsert与heapify操作

5. 堆结构的增大和减少 

6. 优先级队列结构，就是堆结构 

## 前缀树(PrefixTree /Trie)

- 单个字符串中，字符从前到后的加到一棵多叉树上

- 字符放在路上，节点上有专属的数据项（常见的是pass和end值）

- 所有样本都这样添加，如果没有路就新建，如有路就复用

- 沿途节点的pass值增加1，每个字符串结束时来到的节点end值增加1

- 常见操作：

  void insert(String word)  添加某个字符串，可以重复添加，每次算1个
  int search(String word)  查询某个字符串在结构中还有几个
  void delete(String word)  删掉某个字符串，可以重复删除，每次算1个
  int prefixNumber(String word)  查询有多少个字符串，是以word做前缀的

  

## 完全二叉树

​	从上至下，从左往右依次填满的二叉树

## 平衡二叉树

​	每一个子树的左右高度绝对值不超过1

## 二叉搜索树

​	左树都比头节点小，右树都比头节点大

## 并查集

1. 有若干个样本a、b、c、d…类型假设是V
2. 在并查集中一开始认为每个样本都在单独的集合里
3. 用户可以在任何时候调用如下两个方法：

>  boolean isSameSet(V x, V y) : 查询样本x和样本y是否属于一个集合
>  void union(V x, V y) : 把x和y各自所在集合的所有样本合并成一个集合

4. isSameSet和union方法的代价越低越好
5. 每个节点都有一条往上指的指针
6. 节点a往上找到的头节点，叫做a所在集合的代表节点
7. 查询x和y是否属于同一个集合，就是看看找到的代表节点是不是一个
8. 把x和y各自所在集合的所有点合并成一个集合，只需要小集合的代表点挂在大集合的代表点的下方即可

> 优化：
>
> 1. 节点往上找代表点的过程，把沿途的链变成扁平的
> 2. 小集合挂在大集合的下面
> 3. 如果方法调用很频繁，那么单次调用的代价为O(1)，两个方法都如此

​		9. 应用：解决两大块区域的合并问题，常用在图等领域中

## 图

1. 由点的集合和边的集合构成
2. 虽然存在有向图和无向图的概念，但实际上都可以用有向图来表达
3. 边上可能带有权值

# 排序

## 堆排序

1. 先让整个数组都变成大根堆结构，建立堆的过程: 

   >  从上到下的方法，时间复杂度为O(N*logN) 
   >
   >  从下到上的方法，时间复杂度为O(N) 

2. 把堆的最大值和堆末尾的值交换，然后减少堆的大小之后，再去调整堆，一直周而复始，时间复杂度为O(N*logN) 

3. 堆的大小减小成0之后，排序完成 

## 归并排序

1. 整体是递归，左边排好序+右边排好序+merge让整体有序
2. 让其整体有序的过程里用了排外序方法
3. 时间复杂度: O(N*logN)，
4. 额外空间复杂度：merge过程需要辅助数组，所以是O(N)

## 快速排序

1. 快速排序1.0和2.0的时间复杂度分析：

   数组已经有序的时候就是复杂度最高的时候，时间复杂度O(N^2)

2. 随机快排的时间复杂度分析:

   2.1 划分值越靠近中间，性能越好；越靠近两边，性能越差

   2.2 随机选一个数进行划分的目的就是让好情况和差情况都变成概率事件

   2.3 把每一种情况都列出来，会有每种情况下的时间复杂度，但概率都是1/N

   2.4 那么所有情况都考虑，时间复杂度就是这种概率模型下的长期期望！

   2.5 时间复杂度O(N*logN)，额外空间复杂度O(logN)

## 桶排序

​      桶排序思想下的排序：**计数排序** & **基数排序 **

1. 桶排序思想下的排序都是不基于比较的排序
2. 时间复杂度为O(N)，额外空间负载度O(M)
3. 应用范围有限，需要样本的数据状况满足桶的划分 

> 一般来讲，计数排序要求，样本是**整数**，且**范围比较窄**
> 一般来讲，基数排序要求，样本是**10进制**的**正整数**

## 图的拓扑排序

1. 在图中找到所有入度为0的点输出
2. 把所有入度为0的点在图中删掉，继续找入度为0的点输出，周而复始
3. 图的所有点都被删除后，依次输出的顺序就是拓扑排序

>要求：**有向**图且其中**没有环**
>应用：事件安排、编译顺序

## 小结

|          | 时间复杂度 | 额外空间复杂度 | 稳定性 |
| -------- | ---------- | -------------- | ------ |
| 选择排序 | O(N^2)     | O(1)           | 无     |
| 冒泡排序 | O(N^2)     | O(1)           | 有     |
| 插入排序 | O(N^2)     | O(1)           | 有     |
| 归并排序 | O(N*logN)  | O(N)           | 有     |
| 随机快排 | O(N*logN)  | O(logN)        | 无     |
| 堆排序   | O(N*logN)  | O(1)           | 无     |
| 计数排序 | O(N)       | O(M)           | 有     |
| 基数排序 | O(N)       | O(N)           | 有     |

1. 不基于比较的排序，对样本数据有严格要求，不易改写
2. 基于比较的排序，只要规定好两个样本怎么比大小就可以直接复用
3. 基于比较的排序，时间复杂度的极限是O(N**logN)*
4. 时间复杂度O(N*logN)、额外空间复杂度低于O(N)、且稳定的基于比较的排序是不存在的。
5. 为了绝对的速度选快排、为了省空间选堆排、为了稳定性选归并

# 学习与面试技巧

## 算法和数据结构学习的大脉络

1. 知道**怎么算**的算法
2. 知道**怎么试**的算法

## 链表解题的方法论

1. 对于笔试，不用太在乎空间复杂度，一切为了时间复杂度
2. 对于面试，时间复杂度依然放在第一位，但是一定要找到空间最省的方法

## 链表常用数据结构和技巧

1. 使用容器(哈希表、数组等)
2. 快慢指针

## 二叉树的递归套路

1. 假设以X节点为头，假设可以向X左树和X右树要任何信息
2. 在上一步的假设下，讨论以X为头节点的树，得到*答案的可能性*（**难点**）
3. 列出所有可能性后，确定到底需要向左树和右树要什么样的信息
4. 把左树信息和右树信息求全集，就是任何一棵子树都需要返回的信息Info
5. 递归函数都返回Info，每一棵子树都这么要求
6. 写代码，在代码中考虑如何把左树的信息和右树信息整合出整棵树的信息

> 可以解决面试中绝大多数的二叉树问题尤其是树型dp问题

## 贪心算法的解题套路

1. 实现一个不依靠贪心策略的解法X，可以用最暴力的尝试
2. 脑补出贪心策略A、贪心策略B、贪心策略C...
3. 用解法X和对数器，用实验的方式得知哪个贪心策略正确
4. 不要去纠结贪心策略的证明

## 如何搞定图的面试题

1. 先用自己最熟练的方式，实现图结构的表达
2. 在自己熟悉的结构上，实现所有常用的图算法作为模板
3. 把面试题提供的图结构转化为自己熟悉的图结构，再调用模板或改写即可

> 图的算法都不算难，只是coding的代价比较高